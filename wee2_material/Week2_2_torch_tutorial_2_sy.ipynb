{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyeonjungGit/Wello_team1/blob/main/wee2_material/Week2_2_torch_tutorial_2_sy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JFpYA13POXd2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BCyAL3dyOXd6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토치 뉴럴 네트워크 = nn"
      ],
      "metadata": {
        "id": "8UTXvtwSqyuh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_aD0uLjOXd6"
      },
      "source": [
        "# Pytorch Graph\n",
        "`torch.nn` 모듈은 텐서 그래프를 생성하는 다양한 함수를 제공한다. \n",
        "\n",
        "[OFFICAL DOCUMENT](https://pytorch.org/docs/stable/nn.html)\n",
        "\n",
        "# Table of Contents\n",
        "1. [Container](#Container)\n",
        "2. [Layers](#Layers)\n",
        "3. [Loss](#Loss)\n",
        "4. [추가](#To-Learn-More..)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD83YOocOXd8"
      },
      "source": [
        "## Container\n",
        "- [OFFICIAL DOC](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#module)\n",
        "\n",
        "layer들을 어떻게 쌓아서 하나의 model Container로 만들 것인가.\n",
        "\n",
        "Container -> 뼈대. 개별적인 layer들을 어떻게 lapping해서 하나의 모델 컨테이너로 만들 것인가. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swW0tvvLOXd9"
      },
      "source": [
        "### `Module` class \n",
        "- Custom Neural Network를 생성할 때 반드시 `Module` 클래스를 부모 클래스로 상속받아야 함(nn.Module)\n",
        "- 왜냐하면 `Module` 부모 클래스의 변수 및 메소드 사용 가능 (ex. `eval()`, `train()`, `parameters()`, `state_dict()`, `to()`)\n",
        "- `forward()` 메소드는 모든 자식클래스에서 반드시 **오버라이딩** 해야함\n",
        "- [출처](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train() -> True-> require gradiant 가 계속 저장됨 : 백워드시 파라미터가 계속 저장됨.\n",
        "# parameters() -> 학습되는 파라미터와 파라미터의 weight\n",
        "# to -> cpu? gpu? 뭐에 올릴 건지.\n",
        "# foward 메서드는 자식클래스에서 반드시 오버라이딩 해야한다."
      ],
      "metadata": {
        "id": "HUv-VRMU5Ntl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxmY0tS-OXd9"
      },
      "source": [
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_model.jpeg?raw=true\" alt=\"model\" width=600>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VZKTOfJqOXd-"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module): \n",
        "    def __init__(self, input_shape):  #input_shape = input의 차원수\n",
        "        super(Model, self).__init__()  # initialize\n",
        "        self.layer1 = nn.Linear(input_shape, 32)  # output 32\n",
        "        self.layer2 = nn.Linear(32, 64)  # output 64\n",
        "        self.layer_out = nn.Linear(64,1)\n",
        "        \n",
        "        self.relu = nn.ReLU()  # activation\n",
        "\n",
        "    def forward(self, x):  # x= input  # forward 오버라이딩을 하면서 input, output값 지정\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.layer_out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4lgtRKMcOXd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d02aade-00a3-4d7f-8bec-05db1c1e9f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 30])\n",
            "torch.Size([32])\n",
            "torch.Size([64, 32])\n",
            "torch.Size([64])\n",
            "torch.Size([1, 64])\n",
            "torch.Size([1])\n",
            "layer1.weight -> size : torch.Size([32, 30])\n",
            "layer1.bias -> size : torch.Size([32])\n",
            "layer2.weight -> size : torch.Size([64, 32])\n",
            "layer2.bias -> size : torch.Size([64])\n",
            "layer_out.weight -> size : torch.Size([1, 64])\n",
            "layer_out.bias -> size : torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "model = Model(30) \n",
        "\n",
        "for param in model.parameters():\n",
        "    print(param.shape)\n",
        "\n",
        "for name, state in model.state_dict().items():  # 학습되는 파라미터 이름과, weight를 출력해준다. \n",
        "    print(f\"{name} -> size : {state.shape}\")\n",
        "\n",
        "# 학습안된 상태에서는 초기화값만.\n",
        "# parameters() : https://easy-going-programming.tistory.com/11\n",
        "# state_dict() : https://tutorials.pytorch.kr/recipes/recipes/what_is_state_dict.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 내 컴퓨터 환경에서 cuda 쓸 수 있어?\n",
        "torch.cuda.is_available()  \n",
        "\n",
        "# cuda 쓰려면 내 컴퓨터에 gpu가 Nbdia?? , cuda, cudn이 설치되어 있dj야 한다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L83jGqDDwAch",
        "outputId": "6d50ccf2-7204-4cd7-a57e-86577db5eef0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9aucu7uHOXeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983b3ea3-8bf6-47d8-85db-f6f7a8282bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer1): Linear(in_features=30, out_features=32, bias=True)\n",
              "  (layer2): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "model.to(device)  # 커스터마이징한 모델에 device에 올라가게 한다. 이 device에서 연산되는 것."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지는 nn.Module 클래스를 상속받아서 커스터마이징한 뉴럴 네트워크를 만드는 방법. 레이어를 변경해서 커스터마이징 모델 만들때는 상속받아야 한다. \n",
        "\n",
        "객체지향. 정의한 다음 input, output 어떻게 설정할지 forward오버라이딩 하면서 설정함. 아래의 시퀀셜 클래스는 어떨까? "
      ],
      "metadata": {
        "id": "5Rg3GFNM-Z1E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caZPdvpqOXeB"
      },
      "source": [
        "### `Sequntial` class\n",
        "- 여러 layer를 체인처럼 연결한 container\n",
        "- 이전 layer의 output이 다음 layer의 input으로 입력됨 (순차적)\n",
        "- [출처](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)\n",
        "\n",
        "넣은 순서대로 연결된다. \n",
        "output이 input이 된다.\n",
        "한번에 연산되므로 간편하다는 장점이 있음. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZGphSFCfOXeC"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(  # \n",
        "          nn.Linear(30, 32),  # 입력 30, output 32\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(32,64),  # 입력 32, output 64\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64,1)  # 입력 64, output 1\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HYRuf5fwOXeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576099c3-b89a-4822-9ded-fcd90cb5b744"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=30, out_features=32, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인풋값 넣기 x = tensor\n",
        "model(x)"
      ],
      "metadata": {
        "id": "VffJ_ncXyAsK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "422793cf-3ead-4cc1-ecf6-f7fe631a8672"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-86a8852b911d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 인풋값 넣기 x = tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKHmnkicOXeD"
      },
      "source": [
        "## Layers\n",
        "- Linear()\n",
        "    - `input @ weight.T + bias`\n",
        "https://wikidocs.net/55409\n",
        "\n",
        "\n",
        "- LSTM()\n",
        "    - [OFFICAL DOCS](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) \n",
        "    - nn.LSTM(`input_size`, `hidden_size`)\n",
        "        - nn.LSTM()(`input`, (`h_0`, `c_0`))\n",
        "        - `input` shape: (문장 길이, 배치 사이즈, 단어 엠베딩 사이즈 == input_size) 항상 3차원 (xt)\n",
        "        - `hidden_size` shape: (lstm 개수 * 레이어 수 , 배치 사이즈, 히든 사이즈 == hidden size) -> 히든state와 cell state의 shape을 튜플로 묶어서 정의해달라.\n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_lstm.png?raw=true\" width=500>\n",
        "    - [출처](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "56D5KmhWak94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "s6eL5zvralUA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yK0WSgOGOXeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ec1504-d56b-4fe6-91a3-13b718754d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W shape: torch.Size([30, 20])\n",
            "bias shape: torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "model = nn.Linear(20,30) # (★shape20 을 받아서 shape30을 출력한다. ) (input_dim, output_dim) 20을 받아서 30을 출력  # input(1,20) @ (20,30)  -> output (1,30) + bias(30) (브로드캐스팅)\n",
        "print(f\"W shape: {model.weight.shape}\")\n",
        "print(f\"bias shape: {model.bias.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWHIDabIV5ui",
        "outputId": "3b241c63-6c56-44cb-fe91-b6c4d21a6a5e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f45f90570b0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8sH7oL6tOXeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbd18b2-b617-4365-ae05-ae11afadfeb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'coding', '.', 'Just', 'kidding.']\n"
          ]
        }
      ],
      "source": [
        "ex = \"I love coding . Just kidding.\"\n",
        "inputs = ex.split()\n",
        "print(inputs)\n",
        "\n",
        "# 문장길이, 배치사이즈, 단어임베딩사이즈 : (7, 1, 5) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embedding = [torch.randn(1, 5) for _ in range(len(inputs))]\n",
        "input_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOWXnPwiYxe3",
        "outputId": "e1d25fd8-5328-47e5-d259-8ceebe26b813"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]]),\n",
              " tensor([[-0.1661, -1.5228,  0.3817, -1.0276, -0.5631]]),\n",
              " tensor([[-0.8923, -0.0583, -0.1955, -0.9656,  0.4224]]),\n",
              " tensor([[ 0.2673, -0.4212, -0.5107, -1.5727, -0.1232]]),\n",
              " tensor([[ 3.5870, -1.8313,  1.5987, -1.2770,  0.3255]]),\n",
              " tensor([[-0.4791,  1.3790,  2.5286,  0.4107, -0.9880]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "P9mEp504OXeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c140817c-dcfe-415c-95ff-5972d7608392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 word : output shape (torch.Size([1, 1, 5])) / hidden state shape (torch.Size([1, 1, 5]))\n",
            "2 word : output shape (torch.Size([1, 1, 5])) / hidden state shape (torch.Size([1, 1, 5]))\n",
            "3 word : output shape (torch.Size([1, 1, 5])) / hidden state shape (torch.Size([1, 1, 5]))\n",
            "4 word : output shape (torch.Size([1, 1, 5])) / hidden state shape (torch.Size([1, 1, 5]))\n",
            "5 word : output shape (torch.Size([1, 1, 5])) / hidden state shape (torch.Size([1, 1, 5]))\n",
            "6 word : output shape (torch.Size([1, 1, 5])) / hidden state shape (torch.Size([1, 1, 5]))\n",
            "----------------------------------\n",
            "input sequence shape : torch.Size([6, 1, 5])\n",
            "output shape : torch.Size([6, 1, 5])\n",
            "hidden shape : torch.Size([1, 1, 5])\n"
          ]
        }
      ],
      "source": [
        "input_embedding = [torch.randn(1, 5) for _ in range(len(inputs))]  # 임의의 벡터를 만든다. \n",
        "\n",
        "lstm = nn.LSTM(5,5) # (input dim, output dim)  -> input imbedding, hidden states의 dimension을 의미함.\n",
        "hidden = (\n",
        "    torch.randn(1,1,5), # (모든 레이어의 lstm 개수(여기서는 단방향이므로 1개), batch size, hidden_size)   # 임베딩 사이즈처럼 알아서 정하기. hidden_size\n",
        "    torch.randn(1,1,5),  # 만약 역방향으로 쌓는 lstm이 있다면? 순차, 역차를 concat : bilstm. // ElMo방식 -> layer 2개가 된다. \n",
        ")\n",
        "\n",
        "# 한 단어씩 입력 # 토큰 하나씩 lstm 셀에 넣다.\n",
        "for idx, i in enumerate(input_embedding):   # 한 단어씩 들어간다. \n",
        "    out, hidden = lstm(i.view(1,1,-1), hidden)  # Xt 단어('I')가 3차원에 맞춰서 들어가고, hidden states에 initialize한 hidden이 들어간다. -> 그 다음 토큰('love')이 들어갈 때 hidden은 'I'의 히든이 들어간다. \n",
        "    print(f\"{idx+1} word : output shape ({out.shape}) / hidden state shape ({hidden[0].shape})\")\n",
        "\n",
        "assert out.detach().equal(hidden[0].detach())    # 마지막 layer의 hidden과 output은 동일한 텐서로 나오게 된다. \n",
        "\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "# sequence를 입력 # 문장 통째로.\n",
        "input_embedding = torch.cat(input_embedding).view(len(inputs), 1, -1)  # torch.cat(input_embedding) // .view(len(inputs), 1, -1)\n",
        "print(f\"input sequence shape : {input_embedding.shape}\")\n",
        "hidden = (\n",
        "    torch.randn(1,1,5), # (모든 레이어의 lstm 개수, batch size, hidden_size)\n",
        "    torch.randn(1,1,5),\n",
        ")\n",
        "out, hidden = lstm(input_embedding, hidden)  # out = lstm셀 하나에 output으로 나오는 값. hidden = (ht, Ct) 튜플로 엮여서 나온다. \n",
        "print(f\"output shape : {out.shape}\")\n",
        "print(f\"hidden shape : {hidden[0].shape}\")  \n",
        "\n",
        "assert out[-1, : , :].detach().equal(hidden[0][-1, :,:].detach())     # 마지막 워드의 인덱싱 == 히든 마지막은 같다.\n",
        "\n",
        "# 이해안되면 : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM  이거 추천(신승연)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embedding = [torch.randn(1, 5) for _ in range(len(inputs))]  # 임의의 벡터를 만든다. "
      ],
      "metadata": {
        "id": "Dh4HO-e1Gp0f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(input_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvUPadHGrKh",
        "outputId": "ae4db981-fdcc-425a-fcef-4e9adf598936"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5695, -0.1723, -1.9480,  1.2973,  0.7256],\n",
              "        [ 0.0025, -1.5262, -0.1852, -1.5792, -0.4129],\n",
              "        [ 0.2975, -0.8007,  2.1303,  0.9013, -0.2871],\n",
              "        [ 1.1855,  0.1707, -0.3378, -0.5954,  0.0901],\n",
              "        [-0.8346, -1.7004, -0.4168,  0.2970,  1.1335],\n",
              "        [ 0.6245,  0.4144, -2.1325,  0.2176, -1.0425]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(input_embedding).view(len(inputs), 1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX4Xg2YIGmIc",
        "outputId": "f411f7b5-b567-44cf-d003-8fcd455ff2f9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.5695, -0.1723, -1.9480,  1.2973,  0.7256]],\n",
              "\n",
              "        [[ 0.0025, -1.5262, -0.1852, -1.5792, -0.4129]],\n",
              "\n",
              "        [[ 0.2975, -0.8007,  2.1303,  0.9013, -0.2871]],\n",
              "\n",
              "        [[ 1.1855,  0.1707, -0.3378, -0.5954,  0.0901]],\n",
              "\n",
              "        [[-0.8346, -1.7004, -0.4168,  0.2970,  1.1335]],\n",
              "\n",
              "        [[ 0.6245,  0.4144, -2.1325,  0.2176, -1.0425]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(input_embedding).view(len(inputs), 1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78IB0yfmG3je",
        "outputId": "dcd89f1f-968b-401f-fbbf-a297b73ea74e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.5695, -0.1723, -1.9480,  1.2973,  0.7256]],\n",
              "\n",
              "        [[ 0.0025, -1.5262, -0.1852, -1.5792, -0.4129]],\n",
              "\n",
              "        [[ 0.2975, -0.8007,  2.1303,  0.9013, -0.2871]],\n",
              "\n",
              "        [[ 1.1855,  0.1707, -0.3378, -0.5954,  0.0901]],\n",
              "\n",
              "        [[-0.8346, -1.7004, -0.4168,  0.2970,  1.1335]],\n",
              "\n",
              "        [[ 0.6245,  0.4144, -2.1325,  0.2176, -1.0425]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcBN9V_aF8Ni",
        "outputId": "1af436b7-a706-42dc-f7de-642dbe0aeda7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.1384,  0.2476,  0.1431,  0.3465, -0.0565]]],\n",
              "        grad_fn=<StackBackward0>),\n",
              " tensor([[[ 0.1914,  0.3582,  0.2305,  0.6437, -0.2519]]],\n",
              "        grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWqh0jLFGHbU",
        "outputId": "0ace6561-f4f4-4318-ee2a-e703661db65f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0710,  0.3740,  0.4165, -0.1601, -0.0503]],\n",
              "\n",
              "        [[ 0.1865,  0.2676, -0.0076,  0.2607, -0.1015]],\n",
              "\n",
              "        [[-0.0075,  0.1121, -0.0720,  0.0740, -0.1688]],\n",
              "\n",
              "        [[ 0.1752, -0.0274, -0.2696,  0.3723, -0.0740]],\n",
              "\n",
              "        [[-0.0888, -0.0239, -0.2361,  0.1497, -0.1245]],\n",
              "\n",
              "        [[ 0.1384,  0.2476,  0.1431,  0.3465, -0.0565]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7W8jXimOXeE"
      },
      "source": [
        "## Activation\n",
        "- nonlinear activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "f9dWNYeMOXeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015f6811-9f12-48cc-c8c2-586c6d987907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Softmax(dim=None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "nn.LeakyReLU()\n",
        "nn.ReLU()\n",
        "nn.Sigmoid()\n",
        "nn.GELU()\n",
        "nn.Tanh()\n",
        "nn.Softmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdLlMN8gOXeF"
      },
      "source": [
        "## Loss\n",
        "- loss = loss_class()\n",
        "    - loss(`y_hat`, `y`)\n",
        "    - `loss().backward()`\n",
        "- Mean Square Error Loss \n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_mse.png?raw=true\" width=200>\n",
        "- Cross Entropy Loss \n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_ce.png?raw=true\" width=200>\n",
        "- Binary Cross Entropy Loss \n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_bce.png?raw=true\" width=500>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균제곱오차 : output과 실제 예측값과의 차이의 제곱의 평균.\n",
        "\n",
        "# corssentropy : 분류에 많이 쓰이는 loss\n",
        "# t = 실제값\n",
        "# f(s)i = 예측값\n",
        "# C = 클래스 개수\n",
        "# loss 쓰이는 이유 ? : loss함수를 미분하기 때문. 뉴럴 네트워크 만들 떄 학습하는 파라미터(weight) 업뎃 기준이 바로 loss.loss\n",
        "# 어떤 loss를 쓰느냐에 따라 내 모델이 어떤 방식으로 학습하느냐가 정해진다. \n",
        "\n"
      ],
      "metadata": {
        "id": "QMwToRUfJALN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "T-E-xUS4OXeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1f45a5-30f7-499e-8741-03c1c6fa80e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# l2 distance loss\n",
        "nn.MSELoss()\n",
        "nn.NLLLoss()\n",
        "\n",
        "# cross entropy\n",
        "## multi class\n",
        "nn.CrossEntropyLoss() # softmax O -> 자동으로 해결된다. output레이어를 굳이 softmax()해주지 않아도 자동실행.\n",
        "\n",
        "## binary class\n",
        "nn.BCELoss()  # -> 활성화함수에output을 넣어야한다.\n",
        "nn.BCEWithLogitsLoss() # sigmoid O + BCELoss() -> sigmoid 자동해결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eyAB7IOHOXeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19efcb45-8caf-4bf1-fc8a-b55a13fbffa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits : tensor([[ 0.2214, -0.0558,  1.2057,  1.9486, -0.0766],\n",
            "        [-0.8562, -0.7870, -0.8161,  0.5470, -1.1707],\n",
            "        [-0.4699, -1.6271, -0.1127,  1.5980, -0.8445]], requires_grad=True)\n",
            "Target: tensor([2, 2, 3])\n",
            "Loss : 1.2612911462783813\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "C = 5\n",
        "logits = torch.randn(batch_size, C, requires_grad=True)  #데이터3개, 클래스 5개 (3,5)shape., requires_grad=True : grad을 이용할거고, 역전파때 이 수치들을 뽑아놔야 한다. -> backward() 메서드 한번만으로 logit의 학습 파라미터가 자동으로 계산된다. \n",
        "print(f\"Logits : {logits}\")   # 정답의 확률값.\n",
        "\n",
        "loss = nn.CrossEntropyLoss()  \n",
        "\n",
        "target = torch.empty(batch_size, dtype = torch.long).random_(C)\n",
        "print(f\"Target: {target}\") # 인덱스2의 레이블이 정답이다. 인덱스 2가 정답이다. 인덱스 3이 정답이다. -> 타겟을 가리킴.\n",
        "\n",
        "loss = loss(logits, target)\n",
        "print(f\"Loss : {loss}\")  # 확률과 정답을 비교하면서, 가중치 수정\n",
        " \n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFXZ_5iyOXeF"
      },
      "source": [
        "## To Learn More..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ZVPCKAB4OXeG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "edc7b987-e630-4ea2-b49e-a65d7b176023"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-f0835be785c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_features'"
          ]
        }
      ],
      "source": [
        "# dropout\n",
        "nn.Dropout()\n",
        "# normalization\n",
        "nn.BatchNorm1d()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob1cZqEuOXeG"
      },
      "outputs": [],
      "source": [
        "# gradient clipping  : 업데이트를 배치마다 할건지, 조금더 기다렸다 할건지?\n",
        "nn.utils.clip_grad()\n",
        "# weight normalizing\n",
        "nn.utils.weight_norm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5XCnZIaOXeG"
      },
      "source": [
        "### Parallel\n",
        "- 여러 gpu, 또는 여러 머신에서 입력 데이터를 분산 처리를 가능하게 함\n",
        "\n",
        "현재는 하나의 머신에서 cpu 연산\n",
        "\n",
        "서버에서는 여러 머신에 대해 한 머신이 여러 gpu를 가지고 있다. 그 gpu를 어떻게 병렬적으로 사용할까? \n",
        "\n",
        "여러 머신 여러 gpu의 gradient를 모아서 계산해야 한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw5inpiAOXeG"
      },
      "outputs": [],
      "source": [
        "nn.DataParallel()    \n",
        "nn.parallel.DistributedDataParallel()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cc8ea02fb777342a894a6da130bb5db32fa16020fe93af80059107733690b37d"
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Week2_2_torch_tutorial_2_sy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}